{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef150f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87475bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality records: 20637\n",
      "Exact duplicate records: 28\n",
      "Cross-class duplicate pairs: 9\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "data_dir = Path(\"../data/raw/PlantVillage\")\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "output_dir = Path(\"../data/splits\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load artifacts from previous notebooks\n",
    "quality_df = pd.read_csv(processed_dir / \"quality_analysis.csv\")\n",
    "exact_df = pd.read_csv(processed_dir / \"exact_duplicates.csv\")\n",
    "cross_df = pd.read_csv(processed_dir / \"cross_class_duplicates.csv\")\n",
    "\n",
    "print(f\"Quality records: {len(quality_df)}\")\n",
    "print(f\"Exact duplicate records: {len(exact_df)}\")\n",
    "print(f\"Cross-class duplicate pairs: {len(cross_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e127e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate exclusions:       14\n",
      "Cross-class duplicate exclusions: 4\n",
      "Quality-based exclusions:         299\n",
      "Total unique exclusions:          312\n",
      "Clean images remaining:           20325\n"
     ]
    }
   ],
   "source": [
    "# Exact duplicates...keep first image in each group, exclude the rest\n",
    "exact_df_sorted = exact_df.sort_values(['group_id', 'image_index'])\n",
    "exact_exclude = set(\n",
    "    exact_df_sorted[exact_df_sorted['image_index'] > 1]['image_path'].tolist()\n",
    ")\n",
    "\n",
    "# Cross-class near-duplicates...remove image2 from pairs 1, 2, 5, 9\n",
    "# Pairs are 0-indexed in the dataframe\n",
    "pairs_to_remove = [0, 1, 4, 8] \n",
    "cross_exclude = set(\n",
    "    cross_df.iloc[pairs_to_remove]['image2'].tolist()\n",
    ")\n",
    "\n",
    "# Quality-based exclusions with class-specific blur thresholds\n",
    "BLUR_THRESHOLDS = {\n",
    "    'Tomato__Tomato_YellowLeaf__Curl_Virus': 25,\n",
    "    'default': 100\n",
    "}\n",
    "BRIGHTNESS_THRESHOLD = 50\n",
    "QUALITY_THRESHOLD = 0.40\n",
    "\n",
    "quality_exclude = set()\n",
    "for _, row in quality_df.iterrows():\n",
    "    blur_thresh = BLUR_THRESHOLDS.get(row['class_name'], BLUR_THRESHOLDS['default'])\n",
    "    if (\n",
    "        row['blur_score'] < blur_thresh or\n",
    "        row['brightness'] < BRIGHTNESS_THRESHOLD or\n",
    "        row['quality_score'] < QUALITY_THRESHOLD\n",
    "    ):\n",
    "        quality_exclude.add(row['image_path'])\n",
    "\n",
    "# Combine all exclusions\n",
    "all_excluded = exact_exclude | cross_exclude | quality_exclude\n",
    "\n",
    "print(f\"Exact duplicate exclusions:       {len(exact_exclude)}\")\n",
    "print(f\"Cross-class duplicate exclusions: {len(cross_exclude)}\")\n",
    "print(f\"Quality-based exclusions:         {len(quality_exclude)}\")\n",
    "print(f\"Total unique exclusions:          {len(all_excluded)}\")\n",
    "print(f\"Clean images remaining:           {len(quality_df) - len(all_excluded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c5f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean images: 20325\n",
      "\n",
      "Per-class counts after filtering:\n",
      "class_name\n",
      "Tomato__Tomato_YellowLeaf__Curl_Virus          3138\n",
      "Tomato_Bacterial_spot                          2111\n",
      "Tomato_Septoria_leaf_spot                      1761\n",
      "Tomato_Late_blight                             1727\n",
      "Tomato_Spider_mites_Two_spotted_spider_mite    1673\n",
      "Tomato_healthy                                 1583\n",
      "Pepper__bell___healthy                         1475\n",
      "Tomato__Target_Spot                            1402\n",
      "Potato___Early_blight                          1000\n",
      "Potato___Late_blight                            999\n",
      "Pepper__bell___Bacterial_spot                   995\n",
      "Tomato_Early_blight                             991\n",
      "Tomato_Leaf_Mold                                945\n",
      "Tomato__Tomato_mosaic_virus                     373\n",
      "Potato___healthy                                152\n"
     ]
    }
   ],
   "source": [
    "# Build clean dataset\n",
    "clean_df = quality_df[~quality_df['image_path'].isin(all_excluded)].copy()\n",
    "clean_df = clean_df[['image_path', 'class_name']].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total clean images: {len(clean_df)}\")\n",
    "print(f\"\\nPer-class counts after filtering:\")\n",
    "print(clean_df['class_name'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363fa0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mappings saved.\n",
      "\n",
      "Class index mapping:\n",
      "  0: Pepper__bell___Bacterial_spot\n",
      "  1: Pepper__bell___healthy\n",
      "  2: Potato___Early_blight\n",
      "  3: Potato___Late_blight\n",
      "  4: Potato___healthy\n",
      "  5: Tomato_Bacterial_spot\n",
      "  6: Tomato_Early_blight\n",
      "  7: Tomato_Late_blight\n",
      "  8: Tomato_Leaf_Mold\n",
      "  9: Tomato_Septoria_leaf_spot\n",
      "  10: Tomato_Spider_mites_Two_spotted_spider_mite\n",
      "  11: Tomato__Target_Spot\n",
      "  12: Tomato__Tomato_YellowLeaf__Curl_Virus\n",
      "  13: Tomato__Tomato_mosaic_virus\n",
      "  14: Tomato_healthy\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "classes = sorted(clean_df['class_name'].unique())\n",
    "class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
    "index_to_class = {idx: cls for cls, idx in class_to_index.items()}\n",
    "\n",
    "clean_df['class_index'] = clean_df['class_name'].map(class_to_index)\n",
    "\n",
    "# Save mappings\n",
    "with open(processed_dir / 'class_to_index.json', 'w') as f:\n",
    "    json.dump(class_to_index, f, indent=2)\n",
    "\n",
    "with open(processed_dir / 'index_to_class.json', 'w') as f:\n",
    "    json.dump(index_to_class, f, indent=2)\n",
    "\n",
    "print(\"Class mappings saved.\")\n",
    "print(f\"\\nClass index mapping:\")\n",
    "for cls, idx in class_to_index.items():\n",
    "    print(f\"  {idx}: {cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0d104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 14227 images\n",
      "Val:   3049 images\n",
      "Test:  3049 images\n"
     ]
    }
   ],
   "source": [
    "# Stratified train/val/test split\n",
    "RANDOM_SEED = 42\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "# First split: train vs temp (val + test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    clean_df,\n",
    "    test_size=(VAL_RATIO + TEST_RATIO),\n",
    "    stratify=clean_df['class_name'],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Second split: val vs test from temp\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['class_name'],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} images\")\n",
    "print(f\"Val:   {len(val_df)} images\")\n",
    "print(f\"Test:  {len(test_df)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45860397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (higher = rarer class):\n",
      "  Potato___healthy                                   8.9478\n",
      "  Tomato__Tomato_mosaic_virus                        3.6340\n",
      "  Tomato_Leaf_Mold                                   1.4327\n",
      "  Tomato_Early_blight                                1.3667\n",
      "  Pepper__bell___Bacterial_spot                      1.3627\n",
      "  Potato___Late_blight                               1.3569\n",
      "  Potato___Early_blight                              1.3550\n",
      "  Tomato__Target_Spot                                0.9668\n",
      "  Pepper__bell___healthy                             0.9191\n",
      "  Tomato_healthy                                     0.8560\n",
      "  Tomato_Spider_mites_Two_spotted_spider_mite        0.8100\n",
      "  Tomato_Late_blight                                 0.7845\n",
      "  Tomato_Septoria_leaf_spot                          0.7692\n",
      "  Tomato_Bacterial_spot                              0.6417\n",
      "  Tomato__Tomato_YellowLeaf__Curl_Virus              0.4317\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights from training split only\n",
    "class_counts = train_df['class_name'].value_counts()\n",
    "total_train = len(train_df)\n",
    "n_classes = len(classes)\n",
    "\n",
    "class_weights = {}\n",
    "for cls in classes:\n",
    "    count = class_counts.get(cls, 1)\n",
    "    weight = total_train / (n_classes * count)\n",
    "    class_weights[class_to_index[cls]] = round(weight, 4)\n",
    "\n",
    "with open(processed_dir / 'class_weights.json', 'w') as f:\n",
    "    json.dump(class_weights, f, indent=2)\n",
    "\n",
    "print(\"Class weights (higher = rarer class):\")\n",
    "for idx, weight in sorted(class_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {index_to_class[idx]:<50} {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49743f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifests saved:\n",
      "  ../data/splits/train.csv\n",
      "  ../data/splits/val.csv\n",
      "  ../data/splits/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Export split manifests\n",
    "train_df.to_csv(output_dir / 'train.csv', index=False)\n",
    "val_df.to_csv(output_dir / 'val.csv', index=False)\n",
    "test_df.to_csv(output_dir / 'test.csv', index=False)\n",
    "\n",
    "print(\"Manifests saved:\")\n",
    "print(f\"  {output_dir / 'train.csv'}\")\n",
    "print(f\"  {output_dir / 'val.csv'}\")\n",
    "print(f\"  {output_dir / 'test.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7ac79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing config saved.\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessing config\n",
    "config = {\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'split_ratios': {'train': TRAIN_RATIO, 'val': VAL_RATIO, 'test': TEST_RATIO},\n",
    "    'image_size': [224, 224],\n",
    "    'normalization': {\n",
    "        'mean': [0.46, 0.48, 0.42],\n",
    "        'std': [0.21, 0.18, 0.22]\n",
    "    },\n",
    "    'filtering_thresholds': {\n",
    "        'blur_default': 100,\n",
    "        'blur_overrides': {'Tomato__Tomato_YellowLeaf__Curl_Virus': 25},\n",
    "        'brightness_min': BRIGHTNESS_THRESHOLD,\n",
    "        'quality_score_min': QUALITY_THRESHOLD\n",
    "    },\n",
    "    'exclusions': {\n",
    "        'exact_duplicates': len(exact_exclude),\n",
    "        'cross_class_duplicates': len(cross_exclude),\n",
    "        'quality_filtered': len(quality_exclude),\n",
    "        'total_excluded': len(all_excluded)\n",
    "    },\n",
    "    'final_dataset': {\n",
    "        'total_clean': len(clean_df),\n",
    "        'train': len(train_df),\n",
    "        'val': len(val_df),\n",
    "        'test': len(test_df),\n",
    "        'n_classes': n_classes\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(processed_dir / 'preprocessing_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Preprocessing config saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9b0e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation checks...\n",
      "\n",
      "✅ No path overlap across splits\n",
      "✅ No excluded files remain in any split\n",
      "✅ Class indices are contiguous\n",
      "✅ All files exist on disk\n",
      "\n",
      "==================================================\n",
      "FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total clean images : 20325\n",
      "Train              : 14227\n",
      "Val                : 3049\n",
      "Test               : 3049\n",
      "Classes            : 15\n",
      "Excluded total     : 312\n"
     ]
    }
   ],
   "source": [
    "# Validation checks\n",
    "print(\"Running validation checks...\\n\")\n",
    "\n",
    "# 1. No path overlap across splits\n",
    "train_paths = set(train_df['image_path'])\n",
    "val_paths = set(val_df['image_path'])\n",
    "test_paths = set(test_df['image_path'])\n",
    "\n",
    "assert len(train_paths & val_paths) == 0, \"LEAK: train/val overlap\"\n",
    "assert len(train_paths & test_paths) == 0, \"LEAK: train/test overlap\"\n",
    "assert len(val_paths & test_paths) == 0, \"LEAK: val/test overlap\"\n",
    "print(\"✅ No path overlap across splits\")\n",
    "\n",
    "# 2. No excluded files remain\n",
    "assert len(train_paths & all_excluded) == 0, \"Excluded files found in train\"\n",
    "assert len(val_paths & all_excluded) == 0, \"Excluded files found in val\"\n",
    "assert len(test_paths & all_excluded) == 0, \"Excluded files found in test\"\n",
    "print(\"✅ No excluded files remain in any split\")\n",
    "\n",
    "# 3. Class indices are contiguous\n",
    "indices = sorted(index_to_class.keys())\n",
    "assert indices == list(range(n_classes)), \"Class indices are not contiguous\"\n",
    "print(\"✅ Class indices are contiguous\")\n",
    "\n",
    "# 4. All files exist on disk\n",
    "missing = [p for p in clean_df['image_path'] if not Path(p).exists()]\n",
    "assert len(missing) == 0, f\"{len(missing)} files missing from disk\"\n",
    "print(\"✅ All files exist on disk\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"FINAL DATASET SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Total clean images : {len(clean_df)}\")\n",
    "print(f\"Train              : {len(train_df)}\")\n",
    "print(f\"Val                : {len(val_df)}\")\n",
    "print(f\"Test               : {len(test_df)}\")\n",
    "print(f\"Classes            : {n_classes}\")\n",
    "print(f\"Excluded total     : {len(all_excluded)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
